"""
åœé¡¿åˆ†å¥æ¨¡å—ï¼ˆå¯¹è±¡åŒ–ç‰ˆæœ¬ï¼‰
"""
import pandas as pd
import warnings
from typing import List
from core.utils.config_utils import load_key
from core.utils import rprint
from core.utils.models import Sentence, Chunk

warnings.filterwarnings("ignore", category=FutureWarning)


# ------------
# Fix Abnormal Word Timestamps
# ------------

def fix_abnormal_words_in_sentence(sentence: Sentence, max_duration: float = 2.0) -> Sentence:
    """
    ä¿®æ­£å¥å­ä¸­é¦–å°¾çš„å¼‚å¸¸é•¿è¯

    é—®é¢˜ï¼šASR å¯èƒ½å°†é™éŸ³æ®µç®—åˆ°è¯çš„æ—¶é—´æˆ³ä¸­ï¼Œå¯¼è‡´æŸäº›è¯æ—¶é•¿å¼‚å¸¸ï¼ˆå¦‚ >2 ç§’ï¼‰
    è§£å†³ï¼šåªå¤„ç†å¥é¦–/å¥å°¾çš„å¼‚å¸¸è¯ï¼Œç”¨åŒå¥å…¶ä»–è¯çš„å¹³å‡æ—¶é•¿ä½œä¸ºåŸºå‡†

    Args:
        sentence: Sentence å¯¹è±¡
        max_duration: æœ€å¤§åˆç†æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºæ˜¯å¼‚å¸¸

    Returns:
        ä¿®æ­£åçš„ Sentence å¯¹è±¡
    """
    if not sentence.chunks:
        return sentence

    # è®¡ç®—è¿™å¥è¯æ‰€æœ‰è¯çš„å¹³å‡æ—¶é•¿ï¼ˆæ’é™¤å¼‚å¸¸è¯åå†ç®—ï¼‰
    normal_durations = []
    for chunk in sentence.chunks:
        duration = chunk.end - chunk.start
        if duration <= max_duration:
            normal_durations.append(duration)

    # è®¡ç®—å¹³å‡æ—¶é•¿ï¼Œå¦‚æœéƒ½æ˜¯å¼‚å¸¸è¯åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if normal_durations:
        avg_duration = sum(normal_durations) / len(normal_durations)
    else:
        avg_duration = 0.5  # é»˜è®¤å€¼

    # ä¿®æ­£å¼‚å¸¸é•¿è¯
    for i, chunk in enumerate(sentence.chunks):
        duration = chunk.end - chunk.start

        if duration > max_duration:
            is_first = (i == 0)
            is_last = (i == len(sentence.chunks) - 1)

            if is_first:
                # å¥é¦–è¯ï¼šstart è¢«å‰æ‹–ï¼ˆåŒ…å«å‰é¢çš„é™éŸ³ï¼‰ï¼Œä¿®æ­£ start
                original_start = chunk.start
                chunk.start = chunk.end - avg_duration
                rprint(f"[yellow]ä¿®æ­£å¥é¦–è¯ '{chunk.text}': "
                       f"{duration:.2f}s â†’ {avg_duration:.2f}s "
                       f"(start {original_start:.2f}s â†’ {chunk.start:.2f}s)[/yellow]")

            elif is_last:
                # å¥å°¾è¯ï¼šend è¢«åæ‹–ï¼ˆåŒ…å«åé¢çš„é™éŸ³ï¼‰ï¼Œä¿®æ­£ end
                original_end = chunk.end
                chunk.end = chunk.start + avg_duration
                rprint(f"[yellow]ä¿®æ­£å¥å°¾è¯ '{chunk.text}': "
                       f"{duration:.2f}s â†’ {avg_duration:.2f}s "
                       f"(end {original_end:.2f}s â†’ {chunk.end:.2f}s)[/yellow]")

            else:
                # å¥ä¸­è¯ï¼šæƒ…å†µå¤æ‚ï¼Œæš‚ä¸å¤„ç†ï¼Œä»…è®°å½•
                rprint(f"[dim]âš ï¸ å¥ä¸­å¼‚å¸¸è¯ '{chunk.text}': {duration:.2f}s (è·³è¿‡ä¿®æ­£)[/dim]")

    # æ›´æ–°å¥å­çš„æ—¶é—´æˆ³
    sentence.update_timestamps()
    return sentence


def fix_abnormal_words(sentences: List[Sentence], max_duration: float = 2.0) -> List[Sentence]:
    """
    æ‰¹é‡ä¿®æ­£å¥å­ä¸­çš„å¼‚å¸¸é•¿è¯

    Args:
        sentences: Sentence å¯¹è±¡åˆ—è¡¨
        max_duration: æœ€å¤§åˆç†æ—¶é•¿ï¼ˆç§’ï¼‰

    Returns:
        ä¿®æ­£åçš„ Sentence å¯¹è±¡åˆ—è¡¨
    """
    result = []
    fixed_count = 0

    for sentence in sentences:
        fixed = fix_abnormal_words_in_sentence(sentence, max_duration)
        result.append(fixed)

        # ç»Ÿè®¡ä¿®æ­£æ•°é‡
        for chunk in sentence.chunks:
            if chunk.end - chunk.start > max_duration:
                fixed_count += 1

    if fixed_count > 0:
        rprint(f"[cyan]ğŸ”§ å…±ä¿®æ­£ {fixed_count} ä¸ªå¼‚å¸¸é•¿è¯[/cyan]")

    return result


# ------------
# New Object-based Function
# ------------

def split_by_pause(sentences: List[Sentence], pause_threshold: float) -> List[Sentence]:
    """
    æŒ‰åœé¡¿åˆ‡åˆ†ï¼ˆå¯¹è±¡åŒ–ç‰ˆæœ¬ï¼‰

    æ£€æŸ¥æ¯ä¸ªå¥å­å†…éƒ¨ chunks ä¹‹é—´çš„åœé¡¿ï¼Œå¦‚æœåœé¡¿è¶…è¿‡é˜ˆå€¼åˆ™åˆ‡åˆ†å¥å­

    Args:
        sentences: Sentence å¯¹è±¡åˆ—è¡¨
        pause_threshold: åœé¡¿é˜ˆå€¼ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡æ­¤å€¼åˆ™åˆ‡åˆ†

    Returns:
        List[Sentence]: åˆ‡åˆ†åçš„ Sentence å¯¹è±¡åˆ—è¡¨
    """
    # Step 1: å…ˆä¿®å¤å¼‚å¸¸é•¿è¯ï¼ˆå§‹ç»ˆæ‰§è¡Œï¼‰
    sentences = fix_abnormal_words(sentences, max_duration=2.0)

    # Step 2: å¦‚æœåœé¡¿åˆ‡åˆ†æœªå¯ç”¨ï¼Œç›´æ¥è¿”å›
    if pause_threshold <= 0:
        return sentences

    # Step 3: æ£€æŸ¥å¥å­å†…éƒ¨çš„åœé¡¿å¹¶åˆ‡åˆ†
    result = []
    split_count = 0

    for sentence in sentences:
        # å•è¯å¥å­ï¼Œæ— æ³•æ£€æŸ¥é—´éš”ï¼Œç›´æ¥ä¿ç•™
        if len(sentence.chunks) < 2:
            result.append(sentence)
            continue

        # æ‰¾åˆ°éœ€è¦åˆ‡åˆ†çš„ä½ç½®
        split_positions = []
        for i in range(1, len(sentence.chunks)):
            current_chunk = sentence.chunks[i]
            last_chunk = sentence.chunks[i - 1]
            gap = current_chunk.start - last_chunk.end

            if gap > pause_threshold:
                split_positions.append(i)
                rprint(f"[cyan]âœ‚ï¸ æ£€æµ‹åˆ°åœé¡¿ {gap:.2f}s > {pause_threshold}sï¼Œ"
                       f"åœ¨ '{last_chunk.text}' ååˆ‡åˆ†[/cyan]")

        # æ— éœ€åˆ‡åˆ†
        if not split_positions:
            result.append(sentence)
            continue

        # æ‰§è¡Œåˆ‡åˆ†
        start_idx = 0
        for split_idx in split_positions:
            # åˆ›å»ºæ–°å¥å­ï¼ˆä» start_idx åˆ° split_idx-1ï¼‰
            new_chunks = sentence.chunks[start_idx:split_idx]
            new_sentence = Sentence(
                chunks=new_chunks,
                text=''.join(c.text for c in new_chunks),
                start=new_chunks[0].start,
                end=new_chunks[-1].end,
                translation=sentence.translation,
                is_split=True
            )
            result.append(new_sentence)
            split_count += 1
            start_idx = split_idx

        # æ·»åŠ æœ€åä¸€éƒ¨åˆ†
        if start_idx < len(sentence.chunks):
            new_chunks = sentence.chunks[start_idx:]
            new_sentence = Sentence(
                chunks=new_chunks,
                text=''.join(c.text for c in new_chunks),
                start=new_chunks[0].start,
                end=new_chunks[-1].end,
                translation=sentence.translation,
                is_split=True
            )
            result.append(new_sentence)

    if split_count > 0:
        rprint(f"[green]âœ… åœé¡¿åˆ‡åˆ†å®Œæˆï¼š{split_count} ä¸ªå¥å­è¢«åˆ‡åˆ†[/green]")

    return result
