import pandas as pd
import os
import re
import difflib
from rich.panel import Panel
from rich.console import Console
import autocorrect_py as autocorrect
from core.utils import *
from core.utils.models import *
console = Console()

SUBTITLE_OUTPUT_CONFIGS = [ 
    ('src.srt', ['Source']),
    ('trans.srt', ['Translation']),
    ('src_trans.srt', ['Source', 'Translation']),
    ('trans_src.srt', ['Translation', 'Source'])
]


def convert_to_srt_format(start_time, end_time):
    """Convert time (in seconds) to the format: hours:minutes:seconds,milliseconds"""
    def seconds_to_hmsm(seconds):
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = seconds % 60
        milliseconds = int(seconds * 1000) % 1000
        return f"{hours:02d}:{minutes:02d}:{int(seconds):02d},{milliseconds:03d}"

    start_srt = seconds_to_hmsm(start_time)
    end_srt = seconds_to_hmsm(end_time)
    return f"{start_srt} --> {end_srt}"

def remove_punctuation(text):
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^\w\s]', '', text)
    return text.strip()

def clean_word(word):
    """
    Standardized word cleaner (lowercase, no punctuation) for alignment.
    """
    return re.sub(r'[^\w]', '', str(word).lower())

def show_difference(str1, str2):
    """Show the difference positions between two strings"""
    min_len = min(len(str1), len(str2))
    diff_positions = []
    
    for i in range(min_len):
        if str1[i] != str2[i]:
            diff_positions.append(i)
    
    if len(str1) != len(str2):
        diff_positions.extend(range(min_len, max(len(str1), len(str2))))
    
    print("Difference positions:")
    print(f"Expected sentence: {str1}")
    print(f"Actual match: {str2}")
    print("Position markers: " + "".join("^" if i in diff_positions else " " for i in range(max(len(str1), len(str2)))))
    print(f"Difference indices: {diff_positions}")

def get_sentence_timestamps(df_words, df_sentences):
    """
    Get sentence timestamps using difflib-based fuzzy matching.
    Fixed: Uses index mapping to connect clean words back to original DataFrame indices.
    """
    time_stamp_list = []

    # 1. é¢„å¤„ç†ï¼šå»ºç«‹ (æ¸…æ´—åçš„è¯ -> åŸå§‹DataFrameè¡Œå·) çš„æ˜ å°„
    # è¿™æ ·å³ä½¿ä¸­é—´åˆ é™¤äº†ç¬¦å·ï¼Œæˆ‘ä»¬ä¾ç„¶çŸ¥é“ "monthly" åŸæ¥æ˜¯åœ¨ç¬¬ 502 è¡Œ
    original_clean_map = []
    for idx, row in df_words.iterrows():
        word = row['text']
        cleaned = clean_word(word)
        if cleaned:  # åªæœ‰æ¸…æ´—åéç©ºçš„è¯æ‰è¿›å…¥åŒ¹é…åˆ—è¡¨
            original_clean_map.append({
                'text': cleaned,
                'orig_idx': idx  # è®°å½•å®ƒåœ¨ df_words ä¸­çš„çœŸå®ç´¢å¼•
            })
    
    # æå–çº¯å•è¯åˆ—è¡¨ç”¨äº difflib åŒ¹é…
    original_clean_words_only = [item['text'] for item in original_clean_map]

    # è®°å½•å½“å‰åœ¨ "è¿‡æ»¤ååˆ—è¡¨" ä¸­çš„ä½ç½®ï¼Œé¿å…æ¯æ¬¡ä»å¤´æœç´¢
    current_filtered_pos = 0

    # éå†æ¯ä¸€å¥å­—å¹•
    for idx, sentence in df_sentences['Source'].items():
        sentence_words = str(sentence).split()
        sentence_clean_words = [clean_word(w) for w in sentence_words]
        sentence_clean_words = [w for w in sentence_clean_words if w]

        # å¦‚æœå¥å­ä¸ºç©ºï¼ˆå…¨æ˜¯ç¬¦å·ï¼‰ï¼Œä¸ºäº†ä¿æŒæ—¶é—´è¿ç»­æ€§ï¼Œä½¿ç”¨ä¸Šä¸€å¥çš„ç»“æŸæ—¶é—´
        if not sentence_clean_words:
            if not time_stamp_list:
                time_stamp_list.append((0.0, 0.0))
            else:
                last_end = time_stamp_list[-1][1]
                time_stamp_list.append((last_end, last_end))
            continue

        # åœ¨å‰©ä½™çš„æ¸…æ´—åˆ—è¡¨é‡Œè¿›è¡Œæ¨¡ç³ŠåŒ¹é…
        remaining_clean_words = original_clean_words_only[current_filtered_pos:]
        
        s = difflib.SequenceMatcher(None, remaining_clean_words, sentence_clean_words, autojunk=False)
        matching_blocks = s.get_matching_blocks()

        match_start_rel_idx = -1
        match_length = 0

        # å¯»æ‰¾åŒ¹é…å—ï¼šå¿…é¡»åŒ¹é…å¥å­çš„å¼€å¤´ (b_start == 0)
        for a_start, b_start, length in matching_blocks:
            if b_start == 0:  
                match_start_rel_idx = a_start
                match_length = length
                break

        if match_start_rel_idx == -1:
            print(f"\nâš ï¸ Warning: No close match found for sentence: {sentence}")
            # å…œåº•ç­–ç•¥ï¼šæ²¿ç”¨ä¸Šä¸€å¥æ—¶é—´
            if time_stamp_list:
                start_time = time_stamp_list[-1][1]
            else:
                start_time = 0.0
            time_stamp_list.append((start_time, start_time + 1.0))
            continue

        # --- æ ¸å¿ƒä¿®å¤é€»è¾‘ ---
        
        # 1. è®¡ç®—åŒ¹é…å¼€å§‹åœ¨ "è¿‡æ»¤ååˆ—è¡¨" ä¸­çš„ç»å¯¹ä½ç½®
        absolute_start_filtered_idx = current_filtered_pos + match_start_rel_idx
        
        # 2. è®¡ç®—åŒ¹é…ç»“æŸåœ¨ "è¿‡æ»¤ååˆ—è¡¨" ä¸­çš„ç»å¯¹ä½ç½®
        # åˆæ­¥ç»“æŸä½ç½®
        absolute_end_filtered_idx = absolute_start_filtered_idx + match_length - 1
        
        # å¤„ç†éè¿ç»­åŒ¹é…ï¼ˆdifflib å¯èƒ½æŠŠä¸€å¥è¯åˆ‡æˆå‡ æ®µåŒ¹é…ï¼‰
        if match_length < len(sentence_clean_words):
            found_words_count = match_length
            
            for a_start, b_start, length in matching_blocks:
                if a_start <= match_start_rel_idx:
                    continue # è·³è¿‡å·²ç»å¤„ç†çš„ç¬¬ä¸€å—
                
                # å¦‚æœè¿™ä¸€å—æ¥ç€ä¸Šä¸€å—çš„å¥å­å†…å®¹
                if b_start == found_words_count:
                    additional_len = min(length, len(sentence_clean_words) - found_words_count)
                    absolute_end_filtered_idx = current_filtered_pos + a_start + additional_len - 1
                    found_words_count += additional_len
                    
                    if found_words_count >= len(sentence_clean_words):
                        break

        # è¶Šç•Œä¿æŠ¤
        max_idx = len(original_clean_map) - 1
        absolute_start_filtered_idx = min(absolute_start_filtered_idx, max_idx)
        absolute_end_filtered_idx = min(absolute_end_filtered_idx, max_idx)
        # ç¡®ä¿ç»“æŸä¸å°äºå¼€å§‹
        absolute_end_filtered_idx = max(absolute_start_filtered_idx, absolute_end_filtered_idx)

        # 3. ã€å…³é”®ã€‘é€šè¿‡æ˜ å°„è¡¨ï¼Œæ‰¾å› df_words ä¸­çš„çœŸå®ç´¢å¼•
        start_orig_idx = original_clean_map[absolute_start_filtered_idx]['orig_idx']
        end_orig_idx = original_clean_map[absolute_end_filtered_idx]['orig_idx']

        # 4. ä» df_words è·å–çœŸå®æ—¶é—´
        start_time = float(df_words.loc[start_orig_idx, 'start'])
        end_time = float(df_words.loc[end_orig_idx, 'end'])

        # æ—¶é—´æ ¡éªŒï¼šå¦‚æœç»“æŸæ—¶é—´å°äºå¼€å§‹æ—¶é—´ï¼Œå¼ºåˆ¶ä¿®æ­£
        if end_time <= start_time:
             if end_orig_idx < len(df_words) - 1:
                end_time = float(df_words.loc[end_orig_idx + 1, 'end'])
             else:
                end_time = start_time + 0.5

        time_stamp_list.append((start_time, end_time))

        # æ›´æ–°æŒ‡é’ˆï¼šä¸‹ä¸€æ¬¡æœç´¢ä»å½“å‰å¥å­ç»“æŸè¯çš„ä¸‹ä¸€ä¸ªè¯å¼€å§‹
        current_filtered_pos = absolute_end_filtered_idx + 1

    return time_stamp_list

def align_timestamp(df_text, df_translate, subtitle_output_configs: list, output_dir: str, for_display: bool = True):
    """Align timestamps and add a new timestamp column to df_translate"""
    df_trans_time = df_translate.copy()

    # Assign an ID to each word in df_text['text'] and create a new DataFrame
    words = df_text['text'].str.split(expand=True).stack().reset_index(level=1, drop=True).reset_index()
    words.columns = ['id', 'word']
    words['id'] = words['id'].astype(int)

    # Process timestamps â°
    time_stamp_list = get_sentence_timestamps(df_text, df_translate)
    df_trans_time['timestamp'] = time_stamp_list
    df_trans_time['duration'] = df_trans_time['timestamp'].apply(lambda x: x[1] - x[0])

    # Remove gaps ğŸ•³ï¸
    for i in range(len(df_trans_time)-1):
        delta_time = df_trans_time.loc[i+1, 'timestamp'][0] - df_trans_time.loc[i, 'timestamp'][1]
        if 0 < delta_time < 1:
            df_trans_time.at[i, 'timestamp'] = (df_trans_time.loc[i, 'timestamp'][0], df_trans_time.loc[i+1, 'timestamp'][0])

    # Convert start and end timestamps to SRT format
    df_trans_time['timestamp'] = df_trans_time['timestamp'].apply(lambda x: convert_to_srt_format(x[0], x[1]))

    # Polish subtitles: replace punctuation in Translation if for_display
    if for_display:
        df_trans_time['Translation'] = df_trans_time['Translation'].apply(lambda x: re.sub(r'[ï¼Œã€‚]', ' ', x).strip())

    # Output subtitles ğŸ“œ
    def generate_subtitle_string(df, columns):
        result = []
        for i, row in df.iterrows():
            # Safe getter: handle NaN and non-string types
            def safe_get(col):
                val = row.get(col, '')
                return str(val).strip() if pd.notna(val) else ''

            line1 = safe_get(columns[0])
            line2 = safe_get(columns[1]) if len(columns) > 1 else ''
            result.append(f"{i+1}\n{row['timestamp']}\n{line1}\n{line2}\n\n")
        return ''.join(result).strip()

    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        for filename, columns in subtitle_output_configs:
            subtitle_str = generate_subtitle_string(df_trans_time, columns)
            with open(os.path.join(output_dir, filename), 'w', encoding='utf-8') as f:
                f.write(subtitle_str)
    
    return df_trans_time

# âœ¨ Beautify the translation
def clean_translation(x):
    if pd.isna(x):
        return ''
    cleaned = str(x).strip('ã€‚').strip('ï¼Œ')
    return autocorrect.format(cleaned)

def align_timestamp_main():
    df_text = pd.read_excel(_2_CLEANED_CHUNKS)
    df_text['text'] = df_text['text'].str.strip('"').str.strip()
    df_translate = pd.read_excel(_5_SPLIT_SUB)
    df_translate['Translation'] = df_translate['Translation'].apply(clean_translation)
    
    align_timestamp(df_text, df_translate, SUBTITLE_OUTPUT_CONFIGS, _OUTPUT_DIR)
    console.print(Panel("[bold green]ğŸ‰ğŸ“ Subtitles generation completed! Please check in the `output` folder ğŸ‘€[/bold green]"))

    # åˆå¹¶ç©ºå­—å¹•
    merge_empty_subtitle()

def merge_empty_subtitle():
    """åˆå¹¶ç©ºå­—å¹•ï¼šæ£€æŸ¥ç©ºè¡Œçš„å­—å¹•å’Œå‰ä¸€è¡Œæ˜¯å¦è¿ç»­ï¼Œå¦‚æœé—´éš”å°äº0.3ç§’åˆ™åˆ é™¤ç©ºå­—å¹•å¹¶æ›´æ–°å‰å­—å¹•çš„ç»“æŸæ—¶é—´
    åŒæ—¶å¤„ç†å¯¹åº”çš„ä¸­è‹±æ–‡å­—å¹•æ–‡ä»¶"""
    import pysrt
    
    def process_srt_pair(trans_path, src_path):
        """å¤„ç†ä¸­æ–‡å­—å¹•å’Œå¯¹åº”çš„è‹±æ–‡å­—å¹•æ–‡ä»¶å¯¹"""
        if not os.path.exists(trans_path):
            console.print(f"[yellow]âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {trans_path}[/yellow]")
            return
            
        if not os.path.exists(src_path):
            console.print(f"[yellow]âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {src_path}[/yellow]")
            return
            
        try:
            # åŠ è½½ä¸­æ–‡å­—å¹•å’Œè‹±æ–‡å­—å¹•
            trans_subs = pysrt.open(trans_path, encoding='utf-8')
            src_subs = pysrt.open(src_path, encoding='utf-8')
            
            if len(trans_subs) != len(src_subs):
                console.print(f"[red]âŒ å­—å¹•æ–‡ä»¶è¡Œæ•°ä¸åŒ¹é…: {trans_path} ({len(trans_subs)}è¡Œ) vs {src_path} ({len(src_subs)}è¡Œ)[/red]")
                return
            
            # æ‰¾åˆ°éœ€è¦åˆå¹¶çš„ç©ºå­—å¹•æˆ–é‡å¤å­—å¹•ç´¢å¼•
            to_remove = []
            for i in range(len(trans_subs)):
                if i > 0:  # ä»ç¬¬äºŒä¸ªå­—å¹•å¼€å§‹æ£€æŸ¥
                    current_trans = trans_subs[i]
                    prev_trans = trans_subs[i-1]
                    
                    # æ£€æŸ¥å½“å‰ä¸­æ–‡å­—å¹•æ˜¯å¦ä¸ºç©ºï¼ˆå»é™¤ç©ºæ ¼åä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
                    current_text = current_trans.text.strip()
                    prev_text = prev_trans.text.strip()
                    
                    # è®¡ç®—æ—¶é—´é—´éš”ï¼ˆæ¯«ç§’è½¬ç§’ï¼‰
                    time_gap = (current_trans.start.ordinal - prev_trans.end.ordinal) / 1000.0

                    # æƒ…å†µ1: ç©ºå­—å¹•
                    if not current_text and time_gap < 0.5:
                        # æ›´æ–°ä¸­æ–‡å­—å¹•å‰ä¸€ä¸ªå­—å¹•çš„ç»“æŸæ—¶é—´
                        prev_trans.end = current_trans.end

                        # æ›´æ–°è‹±æ–‡å­—å¹•å‰ä¸€ä¸ªå­—å¹•çš„ç»“æŸæ—¶é—´å’Œå†…å®¹
                        prev_src = src_subs[i-1]
                        current_src = src_subs[i]
                        prev_src.end = current_src.end

                        # åˆå¹¶è‹±æ–‡å­—å¹•å†…å®¹ï¼ˆç”¨ç©ºæ ¼è¿æ¥ï¼‰
                        prev_src.text = prev_src.text.strip() + " " + current_src.text.strip()

                        to_remove.append(i)
                        console.print(f"[dim]åˆå¹¶ç©ºå­—å¹•: ç¬¬{i+1}è¡Œ -> ç¬¬{i}è¡Œ[/dim]")

                    # æƒ…å†µ2: è¯‘æ–‡å®Œå…¨é‡å¤
                    elif current_text == prev_text and time_gap < 0.5:
                        # æ›´æ–°ä¸­æ–‡å­—å¹•å‰ä¸€ä¸ªå­—å¹•çš„ç»“æŸæ—¶é—´
                        prev_trans.end = current_trans.end

                        # åŸæ–‡ä¸éœ€è¦åŠ¨ï¼ˆåŒ…æ‹¬æ—¶é—´æˆ³å’Œå†…å®¹ï¼‰
                        to_remove.append(i)
                        console.print(f"[dim]åˆå¹¶é‡å¤å­—å¹•: ç¬¬{i+1}è¡Œ -> ç¬¬{i}è¡Œ[/dim]")
            
            # ä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ç´¢å¼•é—®é¢˜
            for idx in reversed(to_remove):
                del trans_subs[idx]
                del src_subs[idx]
            
            # é‡æ–°ç¼–å·å¹¶ä¿å­˜
            for i, (trans_sub, src_sub) in enumerate(zip(trans_subs, src_subs), 1):
                trans_sub.index = i
                src_sub.index = i
            
            trans_subs.save(trans_path, encoding='utf-8')
            src_subs.save(src_path, encoding='utf-8')
            console.print(f"[green]âœ… å¤„ç†å®Œæˆ: {trans_path} å’Œ {src_path}[/green]")
            
        except Exception as e:
            console.print(f"[red]âŒ å¤„ç†å¤±è´¥ {trans_path} å’Œ {src_path}: {str(e)}[/red]")
    
    # å®šä¹‰å­—å¹•æ–‡ä»¶å¯¹
    subtitle_pairs = [
        (os.path.join(_OUTPUT_DIR, 'trans.srt'), os.path.join(_OUTPUT_DIR, 'src.srt'))
    ]
    
    console.print(Panel("[bold blue]ğŸ” å¼€å§‹æ£€æŸ¥å¹¶åˆå¹¶ç©ºå­—å¹•...[/bold blue]"))
    
    # å¤„ç†æ‰€æœ‰å­—å¹•å¯¹
    for trans_path, src_path in subtitle_pairs:
        process_srt_pair(trans_path, src_path)
    
    console.print(Panel("[bold green]ğŸ‰ ç©ºå­—å¹•åˆå¹¶å®Œæˆï¼[/bold green]"))    

if __name__ == '__main__':
    align_timestamp_main()